# NiN

- NiN 块
  
  > 1 个常规卷积层 + 2 个 1x1 卷积层
  > 
  > 其中，常规卷积层，可以选择卷积核的大小
  > 
  > 1x1 卷积层，核的高 / 宽，只能是 1x1
  > 
  > 常规卷积层，输出通道数是 $C_{out}$ 
  > 
  > 1x1 卷积层，输入 / 输出通道数都是 $C_{out}$ .
  > 
  > 1x1 卷积层，本身不改变特征图的高 / 宽
  > 
  > 所以， 这里的 1x1 卷积层，不改变特征图的高 / 宽 / 通道数，即改变特征图的形状。
  > 
  > 每个卷积层，后面都跟一个 `ReLU` 层，提供非线性性

- 网络结构
  
  > 四个 NiN 块
  > 
  > 每个 NiN 块，后面都跟一个最大汇聚层
  > 
  > 每个最大汇聚层，令特征图的高 / 宽，约分别减半
  > 
  > 第三个汇聚层后面，跟一个 `Dropout` 层，降低模型容量，减轻过拟合
  > 
  > 最后的 NiN 块，将通道数，降为 10 ，并且此时每个通道的高宽已经较少，为 5x5
  > 
  > 再跟一个全局均值汇聚，降每个通道都压缩为一个值，得 10x1x1 
  > 
  > 展开后，得10个类别得概率。

- 参数个数
  
  > 约 2M 个参数
  > 
  > 计算过程 [NiN_analysis.ipynb](https://github.com/garrisonz/reproduce/blob/main/NiN/NiN_analysis.ipynb) 
  > 
  > 这里，采用的是 输入图像 1 通道，预测类别共 10 个。
  > 
  > 若用于 ImageNet, 考虑只更改输入通道为 3， 预测类别为 1000.则，总的参数个数的数量级别不变，仍然小于 10M 个参数
  > 
  > ![](https://github.com/garrisonz/reproduce/blob/main/NiN/NiN.png?raw=true)

##### 特点

- 去掉全连接层
  
  > 展开 + 全连接层 $\to$ NiN 块 + 全局汇聚层
  > 
  > 其中，NIN 块降通道数，下降为类别数
  > 
  > 全局汇聚层，降每个通道，降维为一个概率值
  > 
  > 没有全连接层，参数个数少很多，模型容量较低，减轻过拟合
