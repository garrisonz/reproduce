{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d212cde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T03:10:21.245289Z",
     "start_time": "2022-06-23T03:10:20.830877Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b560380b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T03:10:23.117382Z",
     "start_time": "2022-06-23T03:10:22.802223Z"
    }
   },
   "outputs": [],
   "source": [
    "AlexNet = nn.Sequential(nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(256 * 6 * 6, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "                    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "                    nn.Linear(4096, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b7d5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T03:10:24.419816Z",
     "start_time": "2022-06-23T03:10:24.365817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([1, 96, 55, 55])\n",
      "ReLU output shape:\t torch.Size([1, 96, 55, 55])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 27, 27])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 27, 27])\n",
      "ReLU output shape:\t torch.Size([1, 256, 27, 27])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 13, 13])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 13, 13])\n",
      "ReLU output shape:\t torch.Size([1, 384, 13, 13])\n",
      "Conv2d output shape:\t torch.Size([1, 384, 13, 13])\n",
      "ReLU output shape:\t torch.Size([1, 384, 13, 13])\n",
      "Conv2d output shape:\t torch.Size([1, 256, 13, 13])\n",
      "ReLU output shape:\t torch.Size([1, 256, 13, 13])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 6, 6])\n",
      "Flatten output shape:\t torch.Size([1, 9216])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 3, 224, 224)\n",
    "for layer in AlexNet:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa5b461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T03:11:23.471388Z",
     "start_time": "2022-06-23T03:11:23.425177Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:\t96*3*11*11*55*55+96*55*55\t= 105705600\n",
      "ReLU:\t96*55*55\t= 290400\n",
      "MaxPool2d:\t96*27*27*3*3\t= 629856\n",
      "Conv2d:\t256*96*5*5*27*27+256*27*27\t= 448084224\n",
      "ReLU:\t256*27*27\t= 186624\n",
      "MaxPool2d:\t256*13*13*3*3\t= 389376\n",
      "Conv2d:\t384*256*3*3*13*13+384*13*13\t= 149585280\n",
      "ReLU:\t384*13*13\t= 64896\n",
      "Conv2d:\t384*384*3*3*13*13+384*13*13\t= 224345472\n",
      "ReLU:\t384*13*13\t= 64896\n",
      "Conv2d:\t256*384*3*3*13*13+256*13*13\t= 149563648\n",
      "ReLU:\t256*13*13\t= 43264\n",
      "MaxPool2d:\t256*6*6*3*3\t= 82944\n",
      "Linear:\t4096*9216+4096\t = 37752832\n",
      "ReLU:\t4096\t= 4096\n",
      "Linear:\t4096*4096+4096\t = 16781312\n",
      "ReLU:\t4096\t= 4096\n",
      "Linear:\t1000*4096+1000\t = 4097000\n",
      "1079044672 = 1.1G multiple-add operations\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "sum = 0\n",
    "for layer in AlexNet:\n",
    "    X = layer(X)\n",
    "    l_name = layer.__class__.__name__\n",
    "    num = 0\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        w_size = list(layer.weight.shape)\n",
    "        b_size = layer.bias.shape[0]\n",
    "        num = np.prod(w_size) * np.prod(X.shape[2:]) + b_size * np.prod(X.shape[2:])\n",
    "        \n",
    "        print(l_name, end=':\\t')\n",
    "        print(*w_size, *X.shape[2:], sep='*', end='')\n",
    "        print(f'+{b_size}*{X.shape[2]}*{X.shape[3]}\\t= {num}')\n",
    "    if isinstance(layer, nn.ReLU):\n",
    "        num = np.prod(X.shape[1:])\n",
    "        \n",
    "        print(l_name, end=':\\t')\n",
    "        print(*X.shape[1:], sep='*', end='')\n",
    "        print(f'\\t= {num}')\n",
    "        \n",
    "    if isinstance(layer, nn.MaxPool2d):\n",
    "        k = layer.kernel_size\n",
    "        num = np.prod(X.shape[1:]) * k * k \n",
    "        \n",
    "        print(l_name, end=':\\t')\n",
    "        print(*X.shape[1:], sep='*', end='')\n",
    "        print(f'*{k}*{k}\\t= {num}')\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        w_size = list(layer.weight.shape)\n",
    "        b_size = layer.bias.shape[0]\n",
    "        parm_num = np.prod(w_size) + b_size\n",
    "        \n",
    "        print(l_name, end=':\\t')\n",
    "        print(*w_size, sep='*', end= '')\n",
    "        print(f'+{b_size}\\t = {parm_num}')\n",
    "    sum += num\n",
    "print(f'{sum} = {round(sum / 1000 / 1000 / 1000, 1)}G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04206f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T03:10:28.304481Z",
     "start_time": "2022-06-23T03:10:28.290839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d:\t96*3*11*11+96\t = 34944\n",
      "Conv2d:\t256*96*5*5+256\t = 614656\n",
      "Conv2d:\t384*256*3*3+384\t = 885120\n",
      "Conv2d:\t384*384*3*3+384\t = 1327488\n",
      "Conv2d:\t256*384*3*3+256\t = 884992\n",
      "Linear:\t4096*9216+4096\t = 37752832\n",
      "Linear:\t4096*4096+4096\t = 16781312\n",
      "Linear:\t1000*4096+1000\t = 4097000\n",
      "62378344 = 62.4M\n"
     ]
    }
   ],
   "source": [
    "p_sum = 0\n",
    "for layer in AlexNet:\n",
    "    if isinstance(layer, (nn.Linear, nn.Conv2d)):        \n",
    "        w_size = list(layer.weight.shape)\n",
    "        b_size = layer.bias.shape[0]\n",
    "        parm_num = np.prod(w_size) + b_size\n",
    "        p_sum += parm_num\n",
    "        \n",
    "        print(layer.__class__.__name__, end=':\\t')\n",
    "        print(*w_size, sep='*', end= '')\n",
    "        print(f'+{b_size}\\t = {parm_num}')\n",
    "print(f'{p_sum} = {round(p_sum / 1000 / 1000, 1)}M')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
